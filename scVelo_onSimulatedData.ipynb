{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply scVelo to simulated data\n",
    "---------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we want to apply scVelo to our simulated data. This code follows the struture of the notebook of scVelo **Dynamical Modeling** (https://github.com/theislab/scvelo_notebooks/blob/master/DynamicalModeling.ipynb).\n",
    "\n",
    "First of all, the input data for scVelo are two count matrices of pre-mature (unspliced) and mature (spliced) abundances,\n",
    "which can be obtained from standard sequencing protocols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Import packages**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update to the latest version, if not done yet.\n",
    "!pip install scvelo --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy\n",
    "import scvelo as scv\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import anndata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "from scvelo import logging as logg\n",
    "from scvelo import settings\n",
    "from scvelo.core import get_n_jobs, parallelize\n",
    "from scvelo.preprocessing.moments import get_connectivities\n",
    "from scvelo.tools.utils import make_unique_list, test_bimodality\n",
    "from scvelo import logging as logg\n",
    "from scvelo.core import clipped_log, invert, SplicingDynamics\n",
    "from scvelo.preprocessing.moments import get_connectivities\n",
    "from scvelo.tools.utils import make_dense, round\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv.settings.verbosity = 3  # show errors(0), warnings(1), info(2), hints(3)\n",
    "scv.settings.presenter_view = True  # set max width size for presenter view\n",
    "scv.settings.set_figure_params('scvelo')  # for beautified visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Read your data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read your data file (loom, h5ad, csv, ...) and store the data matrix (``adata.X``), annotation of cells / observations (``adata.obs``) and genes / variables (``adata.var``), unstructured annotation such as graphs (``adata.uns``) and additional data layers where spliced and unspliced counts are stored (``adata.layers``) .\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we are going to load the data we have already simulated using file *dataSimulationScVelo.r*.\n",
    "We can decide here which type of simulation we want to load.\n",
    "We can set \n",
    "- **model** (*NormInd*, for Normal Independent model, or *Demings*, for Deming Residuals model)\n",
    "- **typeSW** (*SW1* for common switching time, or *SW2* for cluster-specific switching points)\n",
    "- **typeT** (**T1** vs **T2** vs **T3**, determining the number of subgroups)\n",
    "- **typeD** (**D1**, for Poisson distributed, and **D4**: Negative Binomial distributed bayVel data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- input parameters\n",
    "pathToYourDirectory = \"pathToYourDirectory\"\n",
    "model = \"Demings\"\n",
    "typeSW = \"SW1\"\n",
    "typeT = \"T1\"\n",
    "typeD = \"D1\"\n",
    "\n",
    "\n",
    "# --- Set the name of the simulation\n",
    "n_genes = \"2000\"\n",
    "nameSIM =  str(typeSW) + \"-\" + str(typeT) + \"-\" +str(typeD) \n",
    "path = pathToYourDirectory + \"/simulations/\" + nameSIM + \"/\"\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = scanpy.AnnData(pd.read_csv(path + nameSIM + \"_\" + n_genes + \"_\" + model + \"_Ms.csv\"))\n",
    "# unspliced and spliced counts\n",
    "adata.layers[\"Ms\"] = pd.DataFrame(pd.read_csv(path + nameSIM + \"_\" + n_genes + \"_\" + model + \"_Ms.csv\"))\n",
    "adata.layers[\"Mu\"] = pd.DataFrame(pd.read_csv(path + nameSIM + \"_\" + n_genes + \"_\" + model + \"_Mu.csv\"))\n",
    "\n",
    "# auxiliary files\n",
    "adata.obs = pd.DataFrame(pd.read_csv(nameSIM + \"_obs.csv\"))\n",
    "adata.var = pd.DataFrame(pd.read_csv(nameSIM + \"_var.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Basic preprocessing**\n",
    "\n",
    "\n",
    "The pre-processing is skipped, since we have already simulated continuous data, following scVelo likelihood (or simulation structure). \n",
    "Avoiding this pre-processing here is in accordance with *scvelo.datasets.simulation* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv.pp.neighbors(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = adata.var[\"index\"]\n",
    "adata.var_names = [str(i) for i in index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Dynamical Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv.tl.recover_dynamics(adata, fit_basal_transcription = True, var_names = \"all\") # We assume that there is basal transcription, since we have simulated alpha > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv.tl.velocity(adata, mode='dynamical', fit_offset = True)\n",
    "scv.tl.velocity_graph(adata)\n",
    "velocity = pd.DataFrame(np.asmatrix(adata.layers[\"velocity\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv.pl.velocity_embedding(adata, arrow_length=8, arrow_size=1, dpi=300, save = path + \"/scVelo_velocityUmap.pdf\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToSave = path + \"/res_sim_\" + nameSIM + \"_\" + str(n_genes) + \"genes_\" + str(model) + \"_scVelo_\"\n",
    "adata.write(pathToSave + \".h5ad\")\n",
    "adata.write_csvs(pathToSave + \".csv\", skip_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genes = adata.var['fit_likelihood'].sort_values(ascending=False).index[:300]\n",
    "top_genes = pd.DataFrame(data=top_genes)\n",
    "top_genes.to_csv(pathToSave + 'top_genes.csv', index=False)\n",
    "\n",
    "# transcription, splicing and degradation rate and steady states\n",
    "alpha = pd.DataFrame(np.asmatrix(adata.var[\"fit_alpha\"])) \n",
    "alpha.to_csv(pathToSave + 'fit_alpha.csv', index=False)\n",
    "beta = pd.DataFrame(np.asmatrix(adata.var[\"fit_beta\"]))\n",
    "beta.to_csv(pathToSave + 'fit_beta.csv', index=False)\n",
    "gamma = pd.DataFrame(np.asmatrix(adata.var[\"fit_gamma\"]))\n",
    "gamma.to_csv(pathToSave + 'fit_gamma.csv', index=False)\n",
    "fit_steady_u = pd.DataFrame(np.asmatrix(adata.var[\"fit_steady_u\"]))\n",
    "fit_steady_u.to_csv(pathToSave + 'fit_steady_u.csv', index=False)\n",
    "fit_steady_s= pd.DataFrame(np.asmatrix(adata.var[\"fit_steady_s\"]))\n",
    "fit_steady_s.to_csv(pathToSave + 'fit_steady_s.csv', index=False)\n",
    "fit_scaling = pd.DataFrame(np.asmatrix(adata.var[\"fit_scaling\"]))\n",
    "fit_scaling.to_csv(pathToSave + 'fit_scaling.csv', index=False)\n",
    "\n",
    "# switching time\n",
    "fit_u0 = pd.DataFrame(np.asmatrix(adata.var[\"fit_u0\"]))\n",
    "fit_u0.to_csv(pathToSave + 'fit_u0.csv', index=False)\n",
    "fit_s0 = pd.DataFrame(np.asmatrix(adata.var[\"fit_s0\"]))\n",
    "fit_s0.to_csv(pathToSave + 'fit_s0.csv', index=False)\n",
    "fit_t_ = pd.DataFrame(np.asmatrix(adata.var[\"fit_t_\"]))\n",
    "fit_t_.to_csv(pathToSave + 'fit_t_.csv', index=False)\n",
    "\n",
    "# time\n",
    "fit_t = pd.DataFrame(np.asmatrix(adata.layers[\"fit_t\"]))\n",
    "fit_t.to_csv(pathToSave + 'fit_t.csv', index=False)\n",
    "fit_tau = pd.DataFrame(np.asmatrix(adata.layers[\"fit_tau\"]))\n",
    "fit_tau.to_csv(pathToSave + 'fit_tau.csv', index=False)\n",
    "fit_tau_ = pd.DataFrame(np.asmatrix(adata.layers[\"fit_tau_\"]))\n",
    "fit_tau_.to_csv(pathToSave + 'fit_tau_.csv', index=False)\n",
    "# velocity\n",
    "velocity = pd.DataFrame(np.asmatrix(adata.layers[\"velocity\"]))\n",
    "velocity.to_csv(pathToSave + 'velocity.csv', index=False)\n",
    "velocity_u = pd.DataFrame(np.asmatrix(adata.layers[\"velocity_u\"]))\n",
    "velocity_u.to_csv(pathToSave + 'velocity_u.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save some plots of the gene-specific dynamic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv.pl.velocity(adata, [str(n) for n in range(20)] + [\"20\", \"30\", \"40\", \"50\", \"60\", \"70\", \"80\", \"90\", \"100\", \"110\", \"120\", \"130\", \"140\", \"150\", \"160\", \"170\", \"180\", \"190\", \"200\", \"210\", \"220\", \"230\", \"240\", \"250\", \"260\", \"270\", \"280\", \"290\", \"300\", \"310\", \"320\", \"330\", \"340\", \"350\", \"360\", \"370\", \"380\", \"390\", \"400\", \"410\", \"420\", \"430\", \"440\", \"450\", \"460\", \"470\", \"480\", \"490\", \"500\", \"510\", \"520\", \"530\", \"540\", \"550\", \"560\", \"570\", \"580\", \"590\", \"600\", \"610\", \"620\", \"630\", \"640\", \"650\", \"660\", \"670\", \"680\", \"690\", \"700\"], layers = 'Ms', dpi = 150, ncols = 2, save = pathToSave + '_dynamicGenes.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
